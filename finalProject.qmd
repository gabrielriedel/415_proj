---
title: "Final Project"
author: "Gabe Riedel, Oliver Whitmarsh"
format: 
  html:
    code-tools: true
    toc: true
    embed-resources: true
    html-table-processing: none
editor: source
execute: 
  error: true
  echo: true
  message: false
  warning: false
code-fold: true
---


Propose a Bayesian model - Oliver
Discuss choice of likelihood and assumptions of your model - Oliver
Discuss choice of prior, including some prior predictive tuning - Oliver
Fit the model to the data - Oliver
Perform and summarize posterior inference - Gabe
Perform and summarize posterior prediction - Gabe
Perform and summarize posterior predictive checking or model comparison - Gabe
Perform sensitivity analysis (e.g., how does the posterior change if the prior changes) - Gabe
Compare your results with a comparable frequentist analysis - Oliver
Report conclusions in the context of the research question - Gabe


```{r}
#| output: false
library(tidyverse)
library(brms)
```


## Research Question and Context

Imagine you're watching a baseball game. The first batter up hits a ball off the end of the bat and it just loops over the head of the first baseman; it's a hit! The next batter steps up and hits a rocket of a line drive at 120 mph, but it's right to the shortstop, and he catches it for an out. Who had the better at bat? Who is more likely to get a hit going forward? In the box score, the first player performed better, but a baseball mind will tell you that the second player had a more impressive swing that wil perform better in the log run. Herein lies the flaw of baseball's age old statistic: batting average. Not all hits and outs are made the same. The goal of this project is to dig past the inherent luck that comes with the game and evaluate how good a hit really is. Our research question is what is the expected batting average of a given player? We will use the exit velocity, launch angle, and direction of a batted ball to predict if should be a hit (1) or an out (0).

## Data

```{r read-data}
library(readr)
library(tidyverse)
cp_data <- read_csv("data/cp_bip.csv")
```

```{r clean-data}

cp_clean <- cp_data |>
  filter(BatterTeam == 'CAL_MUS')
```

Our data come from the Cal Poly baseball team. They are every ball put in play in the 2025 season by Cal Poly baseball hitters. These data are recorded with a high speed radar system called Trackman that is present in majority of the college baseball stadiums in the country. Trackman produces CSVs at the end of each game where each row represents a play in the game and contains information on the ball flight after it is hit as well as the result of the play. Trackman is a highly accurate radar system designed for high speed ball tracking. Our data are a concatenation of the CSVs from each game in Cal Poly's 2025 season. Our three parameters used to predict whether a ball in play is a hit or not are exit velocity of the ball off the bat (measured in miles per hour), launch angle of the ball off the bat (measured in degrees), and horizontal direction of the ball off the bat (measured in degrees, if the ball is hit right up the middle the angle is 0, the further left the ball is hit the more neagtive the direction angle and vice versa for balls hit to the right).


Predict Hit from ExitSpeed, Angle, and Direction
```{r}
cp_clean <- cp_clean |>
  mutate(
    ExitSpeed_c = ExitSpeed - mean(ExitSpeed, na.rm = TRUE),
    Angle_c = Angle - mean(Angle, na.rm = TRUE),
    Direction_c = Direction - mean(Direction, na.rm = TRUE)
  )

```

## Propose a Bayesian model
We propose a Bayesian logistic regression model to estimate the probability that a batted ball results in a hit, using three quantitative predictors: ExitSpeed, LaunchAngle, and Direction. The outcome variable, Hit, is binary (1 = hit, 0 = no hit). Because all three predictors are quantitative and have been centered, the intercept in the model reflects the log-odds of a hit given the averages: exit speed, Angle, and Direction.  

The logistic model is: 
logit(P(Hit = 1)) = B_0 + B_1 * ExitSpeed_c + B_2* Angle_c + B_3 * Direction_c

## Discuss choice of likelihood and assumptions of your model 
We use a Bernoulli likelihood in our Bayesian logistic regression model because our response variable, Hit, is binary (1 = hit, 0 = no hit). The likelihood assumes that each observation (each batted ball) has its own chance of being a hit, and that chance is modeled using our predictors — Exit Speed, Launch Angle, and Direction — through a logit (logistic) link.

STILL NEED ASSUMPTIONS
## Discuss choice of prior, including some prior predictive tuning 

To determine priors for our parameters, we based our estimates on Gabe’s knowledge of baseball. We are setting priors for four parameters: B_0, B_1, B_2, and B_3. Starting with the intercept, B_0, we considered the baseline probability of getting a hit when all predictors are at their average values (since we centered them). Based on Gabe’s experience, this probability is around 30%. Converting that to log-odds gives log(0.3 / 0.7) ≈ -0.847. Since we’re not very confident in this estimate, we allow for more flexibility by placing a prior of B_0 ~ N(-0.847, 1.5).

Next, we set a prior for the Exit Speed coefficient. Because we believe that higher exit velocity almost always increases the chance of a hit, we place the prior on positive values. For instance, if a 1 mph increase improves the log-odds of a hit by roughly 0.05, then a prior of B_ExitSpeed_c ~ N(0.05, 0.025) seems reasonable.

Although the relationship between launch angle and the chance of a hit is complex, there is some evidence that moderately increasing launch angle can improve hitting outcomes (e.g., line drives). To reflect this, we place a prior of B_Angle_c ~ N(0.1, 0.2), suggesting a modest expected positive effect, while still allowing for substantial uncertainty in either direction.

Lastly, placing a prior on direction is more challenging, since the relationship between direction and the probability of a hit is not clearly positive or negative. Because of this uncertainty, we assign a prior of B_Direction_c ~ N(0, 0.2), reflecting our belief that the effect is likely small but allowing for a wide range of plausible values.
```{r}
library(brms)

priors <- c(
  prior(normal(-0.847, 1.5), class = "Intercept"),
  prior(normal(0.05, 0.025), class = "b", coef = "ExitSpeed_c"),
  prior(normal(0.1, 0.2), class = "b", coef = "Angle_c"),
  prior(normal(0, 0.2), class = "b", coef = "Direction_c")
)

fit_prior_only <- brm(
  Hit ~ ExitSpeed_c + Angle_c + Direction_c,
  data = cp_clean,  
  family = bernoulli(link = "logit"),
  prior = priors,
  sample_prior = "only",
  chains = 4,
  cores = 4,
  iter = 2000,
  seed = 123
)


```
```{r}
# Simulate predicted hits from the prior
prior_predictions <- posterior_predict(fit_prior_only)

# Calculate the proportion of hits for each simulated dataset
prior_hit_props <- rowMeans(prior_predictions)

# Plot distribution of prior predictive hit proportions
hist(prior_hit_props,
     main = "Prior Predictive Distribution of Hit Proportion",
     xlab = "Proportion of Hits",
     col = "skyblue",
     breaks = 30)

```
The proportion of hits in the prior predictive check still seems too high, so we’re adjusting the prior on the intercept. Since the intercept mostly controls the baseline hit probability when the predictors are at their average, it’s the easiest way to bring the overall predictions down closer to what we expect — around 30%. We will also decrease the mean of the B_ExitSpeed_c, as it might have too large of a positive effect on hit proportion 

```{r}
priors <- c(
  prior(normal(-2.847, 1.5), class = "Intercept"), # decrease mean of intercept by 2
  prior(normal(0.05, 0.025), class = "b", coef = "ExitSpeed_c"),
  prior(normal(0.05, 0.2), class = "b", coef = "Angle_c"),
  prior(normal(0, 0.2), class = "b", coef = "Direction_c")
)

fit_prior_only <- brm(
  Hit ~ ExitSpeed_c + Angle_c + Direction_c,
  data = cp_clean,  
  family = bernoulli(link = "logit"),
  prior = priors,
  sample_prior = "only",
  chains = 4,
  cores = 4,
  iter = 2000,
  seed = 123
)


```

```{r}
# Simulate predicted hits from the prior
prior_predictions <- posterior_predict(fit_prior_only)

# Calculate the proportion of hits for each simulated dataset
prior_hit_props <- rowMeans(prior_predictions)

# Plot distribution of prior predictive hit proportions
hist(prior_hit_props,
     main = "Prior Predictive Distribution of Hit Proportion",
     xlab = "Proportion of Hits",
     col = "skyblue",
     breaks = 30)
```
Now this distribution of the proportion of hits looks a lot better, thus we have finalized our priors. 

## Fit the model to the data

```{r}
# Define priors
priors <- c(
  prior(normal(-2.847, 1.5), class = "Intercept"),  # Decreased intercept mean
  prior(normal(0.05, 0.025), class = "b", coef = "ExitSpeed_c"),
  prior(normal(0.05, 0.2), class = "b", coef = "Angle_c"),
  prior(normal(0, 0.2), class = "b", coef = "Direction_c")
)

# Fit the Bayesian logistic regression model
fit <- brm(
  Hit ~ ExitSpeed_c + Angle_c + Direction_c,
  data = cp_clean,
  family = bernoulli(link = "logit"),
  prior = priors,
  chains = 4,
  cores = 4,
  iter = 2000,
  seed = 123
)

```

```{r}
summary(fit)
```

